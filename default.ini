################
# General XCSF #
################

OMP_NUM_THREADS=2 # number of threads for parallel processing
POP_SIZE=2000 # maximum number of macro-classifiers in the population
MAX_TRIALS=100000 # number of learning trials to perform
POP_INIT=true # whether to fill the initial population with random classifiers
PERF_AVG_TRIALS=1000 # number of trials to average performance output
THETA_MNA=1 # minimum number of classifiers in a match set

######################
# General Classifier #
######################

ALPHA=1.0 # amount to reduce inaccurate classifier's accuracy (1=disabled)
BETA=0.1 # learning rate for updating error, fitness, and set size
DELTA=0.1 # fraction of the population mean fitness below which the
# fitness of a classifier may be considered in its vote for deletion
NU=5.0 # exponent used in calculating classifier accuracy
THETA_DEL=20.0 # min experience before fitness used in probability of deletion
INIT_FITNESS=0.01 # initial classifier fitness
INIT_ERROR=0.0 # initial classifier error
ERR_REDUC=1.0 # amount to reduce an offspring's error (1=disabled)
FIT_REDUC=0.1 # amount to reduce an offspring's fitness (1=disabled)
EPS_0=0.01 # classifier target error, under which fitness is set to 1

###############
# Subsumption #
###############

GA_SUBSUMPTION=true # whether to try and subsume offspring classifiers
SET_SUBSUMPTION=true # whether to perform match set subsumption
THETA_SUB=20.0 # minimum experience of a classifier to become a subsumer
 
#####################
# Genetic Algorithm #
#####################

THETA_GA=50.0 # average match set time between GA invocations
THETA_OFFSPRING=2 # number of offspring to create each GA invocation
P_CROSSOVER=0.80 # probability of applying crossover
P_MUTATION=0.04 # probability of mutation occuring per gene
S_MUTATION=0.1 # maximum amount to mutate a gene
P_FUNC_MUTATION=0.04 # probability of mutating graph/network functions
 
# number of self-adaptive mutation rates
#NUM_SAM=0 # fixed mutation rates for P_MUTATION and S_MUTATION
#NUM_SAM=1 # self-adapts P_MUTATION
#NUM_SAM=2 # self-adapts P_MUTATION and S_MUTATION
NUM_SAM=3 # self-adapts P_MUTATION and S_MUTATION and P_FUNC_MUTATION
muEPS_0=0.01 # minimum value of a self-adaptive mutation rate
 
########################
# Classifier Condition #
########################

MIN_CON=-1.0 # minimum input value
MAX_CON=1.0 # maximum input value

# Condition type
#COND_TYPE=-1# always matching dummy condition
COND_TYPE=0 # hyperrectangles
#COND_TYPE=1 # hyperellipsoids
#COND_TYPE=2 # multi-layer perceptron neural networks
#COND_TYPE=3 # GP trees
#COND_TYPE=4 # dynamical GP graphs
#COND_TYPE=11# both conditions and predictions in single dynamical GP graphs
#COND_TYPE=12# both conditions and predictions in single neural networks

# Tree-GP
GP_NUM_CONS=100 # number of (shared) constants available for GP trees 
GP_INIT_DEPTH=5 # initial depth of GP trees

# DGP
DGP_NUM_NODES=20 # number of nodes in a DGP graph
RESET_STATES=true # whether to reset DGP initial states each trial
MAX_K=2 # maximum number of connections a DGP node may have
MAX_T=10 # maximum number of cycles to update a DGP graph

# Neural network
NUM_HIDDEN_NEURONS=10 # number of hidden neurons
# Neural Network hidden layer activation function
HIDDEN_NEURON_ACTIVATION=0 # Logistic (-1,1)
#HIDDEN_NEURON_ACTIVATION=1 # Rectified linear unit [0,inf)
#HIDDEN_NEURON_ACTIVATION=2 # Gaussian (0,1]
#HIDDEN_NEURON_ACTIVATION=3 # Bent identity (-inf,inf)
#HIDDEN_NEURON_ACTIVATION=4 # TanH (-1,1)
#HIDDEN_NEURON_ACTIVATION=5 # Sinusoid [-1,1]
#HIDDEN_NEURON_ACTIVATION=6 # Soft plus (0,inf)
#HIDDEN_NEURON_ACTIVATION=7 # Identity (-inf,inf)

#########################
# Classifier Prediction #
#########################

# Prediction type
PRED_TYPE=0 # linear least squares
#PRED_TYPE=1 # quadratic least squares
#PRED_TYPE=2 # linear recursive least squares
#PRED_TYPE=3 # quadratic recursive least squares
#PRED_TYPE=4 # stochastic gradient descent multilayer perceptron neural networks

XCSF_ETA=0.1 # learning rate for updating the computed prediction

# Least squares
XCSF_X0=1.0 # prediction weight vector offset value
RLS_SCALE_FACTOR=1000.0 # initial diagonal values of the RLS gain-matrix
RLS_LAMBDA=1.0 # forget rate for RLS (small values may be unstable)

# Neural network
MOMENTUM=0.9 # momentum for gradient descent update
