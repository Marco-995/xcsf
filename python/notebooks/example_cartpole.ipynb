{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example demonstrates the use of experience replay with XCSF\n",
    "Uses the [cart-pole](https://gymnasium.farama.org/environments/classic_control/cart_pole/) problem from OpenAI gymnasium (v.0.28.1)\n",
    "\n",
    "```\n",
    "$ pip install gymnasium[classic-control]\n",
    "\n",
    "```\n",
    "\n",
    "Note: These hyperparameters do not result in consistently optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Final\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xcsf\n",
    "\n",
    "RANDOM_STATE: Final[int] = 0\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise OpenAI Gym problem environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "X_DIM: Final[int] = int(env.observation_space.shape[0])\n",
    "N_ACTIONS: Final[int] = int(env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise XCSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xcs = xcsf.XCS(\n",
    "    x_dim=X_DIM,\n",
    "    y_dim=N_ACTIONS,\n",
    "    n_actions=1,\n",
    "    omp_num_threads=12,\n",
    "    random_state=RANDOM_STATE,\n",
    "    pop_init=False,\n",
    "    max_trials=1,  # one trial per fit()\n",
    "    pop_size=200,\n",
    "    loss_func=\"mse\",\n",
    "    e0=0.001,\n",
    "    alpha=1,\n",
    "    beta=0.05,\n",
    "    condition={\n",
    "        \"type\": \"neural\",\n",
    "        \"args\": {\n",
    "            \"layer_0\": {  # hidden layer\n",
    "                \"type\": \"connected\",\n",
    "                \"activation\": \"selu\",\n",
    "                \"evolve_weights\": True,\n",
    "                \"evolve_neurons\": True,\n",
    "                \"n_init\": 1,\n",
    "                \"n_max\": 100,\n",
    "                \"max_neuron_grow\": 1,\n",
    "            },\n",
    "            \"layer_1\": {  # output layer\n",
    "                \"type\": \"connected\",\n",
    "                \"activation\": \"linear\",\n",
    "                \"evolve_weights\": True,\n",
    "                \"n_init\": 1,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    prediction={\n",
    "        \"type\": \"rls_quadratic\",\n",
    "    },\n",
    ")\n",
    "\n",
    "GAMMA: Final[float] = 0.95  # discount rate for delayed reward\n",
    "epsilon: float = 1  # initial probability of exploring\n",
    "EPSILON_MIN: Final[float] = 0.1  # the minimum exploration rate\n",
    "EPSILON_DECAY: Final[float] = 0.98  # the decay of exploration after each batch replay\n",
    "REPLAY_TIME: Final[int] = 1  # perform replay update every n episodes\n",
    "\n",
    "print(json.dumps(xcs.get_params(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_steps: int = 0  # total number of steps performed\n",
    "MAX_EPISODES: Final[int] = 2000  # maximum number of episodes to run\n",
    "N: Final[int] = 100  # number of episodes to average performance\n",
    "memory: deque[tuple[np.ndarray, int, float, np.ndarray, bool]] = deque(maxlen=50000)\n",
    "scores: deque[float] = deque(maxlen=N)  # used to calculate moving average\n",
    "\n",
    "# for rendering an episode as a gif\n",
    "SAVE_GIF: Final[bool] = True\n",
    "SAVE_GIF_EPISODES: Final[int] = 50\n",
    "\n",
    "frames: list[list[float]] = []\n",
    "fscore: list[float] = []\n",
    "ftrial: list[int] = []\n",
    "\n",
    "\n",
    "def replay(replay_size: int = 5000) -> None:\n",
    "    \"\"\"Performs experience replay updates\"\"\"\n",
    "    batch_size: Final[int] = min(len(memory), replay_size)\n",
    "    batch = random.sample(memory, batch_size)\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "        y_target = reward\n",
    "        if not done:\n",
    "            prediction_array = xcs.predict(next_state.reshape(1, -1))[0]\n",
    "            y_target += GAMMA * np.max(prediction_array)\n",
    "        target = xcs.predict(state.reshape(1, -1))[0]\n",
    "        target[action] = y_target\n",
    "        xcs.fit(\n",
    "            state.reshape(1, -1), target.reshape(1, -1), warm_start=True, verbose=False\n",
    "        )\n",
    "\n",
    "\n",
    "def egreedy_action(state: np.ndarray) -> int:\n",
    "    \"\"\"Selects an action using an epsilon greedy policy\"\"\"\n",
    "    if np.random.rand() < epsilon:\n",
    "        return random.randrange(N_ACTIONS)\n",
    "    prediction_array = xcs.predict(state.reshape(1, -1))[0]\n",
    "    # break ties randomly\n",
    "    best_actions = np.where(prediction_array == prediction_array.max())[0]\n",
    "    return int(np.random.choice(best_actions))\n",
    "\n",
    "\n",
    "def episode(episode_nr: int, create_gif: bool) -> tuple[float, int]:\n",
    "    \"\"\"Executes a single episode, saving to memory buffer\"\"\"\n",
    "    episode_score: float = 0\n",
    "    episode_steps: int = 0\n",
    "    state: np.ndarray = env.reset()[0]\n",
    "    while True:\n",
    "        action = egreedy_action(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_steps += 1\n",
    "        episode_score += reward\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        if create_gif:\n",
    "            frames.append(env.render())\n",
    "            fscore.append(episode_score)\n",
    "            ftrial.append(episode_nr)\n",
    "        if done:\n",
    "            if create_gif:\n",
    "                for _ in range(100):\n",
    "                    frames.append(frames[-1])\n",
    "                    fscore.append(fscore[-1])\n",
    "                    ftrial.append(ftrial[-1])\n",
    "            break\n",
    "        state = next_state\n",
    "    return episode_score, episode_steps\n",
    "\n",
    "\n",
    "# learning episodes\n",
    "for ep in range(MAX_EPISODES):\n",
    "    gif: bool = False\n",
    "    if SAVE_GIF and ep % SAVE_GIF_EPISODES == 0:\n",
    "        gif = True\n",
    "    # execute a single episode\n",
    "    ep_score, ep_steps = episode(ep, gif)\n",
    "    # perform experience replay updates\n",
    "    if ep % REPLAY_TIME == 0:\n",
    "        replay()\n",
    "    # display performance\n",
    "    total_steps += ep_steps\n",
    "    scores.append(ep_score)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\n",
    "        f\"episodes={ep} \"\n",
    "        f\"steps={total_steps} \"\n",
    "        f\"score={mean_score:.2f} \"\n",
    "        f\"epsilon={epsilon:.5f} \"\n",
    "        f\"error={xcs.error():.5f} \"\n",
    "        f\"msize={xcs.mset_size():.2f}\"\n",
    "    )\n",
    "    # is the problem solved?\n",
    "    if ep > N and mean_score > env.spec.reward_threshold:\n",
    "        print(\n",
    "            f\"solved after {ep} episodes: \"\n",
    "            f\"mean score {mean_score:.2f} > {env.spec.reward_threshold:.2f}\"\n",
    "        )\n",
    "        break\n",
    "    # decay the exploration rate\n",
    "    if epsilon > EPSILON_MIN:\n",
    "        epsilon *= EPSILON_DECAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final exploit episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0\n",
    "ep_score, ep_steps = episode(ep, SAVE_GIF)\n",
    "print(f\"score = {ep_score}, steps = {ep_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the learning episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SAVE_GIF:\n",
    "    # add score and episode nr\n",
    "    rcParams[\"font.family\"] = \"monospace\"\n",
    "    bbox = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "    annotated_frames = list()\n",
    "    bar = tqdm(total=len(frames), position=0, leave=True)\n",
    "    for i in range(len(frames)):\n",
    "        fig = plt.figure(dpi=90)\n",
    "        fig.set_size_inches(3, 3)\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.imshow(frames[i])\n",
    "        plt.axis(\"off\")\n",
    "        strial = str(ftrial[i])\n",
    "        sscore = str(int(fscore[i]))\n",
    "        text = f\"episode = {strial:3s}, score = {sscore:3s}\"\n",
    "        ax.annotate(text, xy=(0, 100), xytext=(-40, 1), fontsize=12, bbox=bbox)\n",
    "        fig.canvas.draw()\n",
    "        annotated_frames.append(np.asarray(fig.canvas.renderer.buffer_rgba()))\n",
    "        plt.close(fig)\n",
    "        bar.refresh()\n",
    "        bar.update(1)\n",
    "    bar.close()\n",
    "    # write gif\n",
    "    imageio.mimsave(\"animation.gif\", annotated_frames, duration=30)\n",
    "    display(Image(open(\"animation.gif\", \"rb\").read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()  # close Gym"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
